{
 "metadata": {
  "name": "",
  "signature": "sha256:a8ac94e01c4b03125767769e054f24edcb2340dc268207c77173d8f3d3b72181"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading the data\n",
      "\n",
      "We can load the data using our usual Pandas read_csv command.\n",
      "\n",
      "We have two datasets available to us:\n",
      "1. The training set which we will use to build and verify our model\n",
      "1. The final test set which we will need to predict salaries for without knowing the right answer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv(\"train.csv\")\n",
      "print data.head()\n",
      "\n",
      "submission_test = pd.read_csv(\"test.csv\")\n",
      "print submission_test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         Id                                              Title  \\\n",
        "0  12612628                        Engineering Systems Analyst   \n",
        "1  12612830                            Stress Engineer Glasgow   \n",
        "2  12612844                   Modelling and simulation analyst   \n",
        "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
        "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
        "\n",
        "                                     FullDescription  \\\n",
        "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
        "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
        "2  Mathematical Modeller / Simulation Analyst / O...   \n",
        "3  Engineering Systems Analyst / Mathematical Mod...   \n",
        "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
        "\n",
        "                         LocationRaw LocationNormalized ContractType  \\\n",
        "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
        "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
        "2  Hampshire, South East, South East          Hampshire          NaN   \n",
        "3     Surrey, South East, South East             Surrey          NaN   \n",
        "4     Surrey, South East, South East             Surrey          NaN   \n",
        "\n",
        "  ContractTime                       Company          Category  \\\n",
        "0    permanent  Gregory Martin International  Engineering Jobs   \n",
        "1    permanent  Gregory Martin International  Engineering Jobs   \n",
        "2    permanent  Gregory Martin International  Engineering Jobs   \n",
        "3    permanent  Gregory Martin International  Engineering Jobs   \n",
        "4    permanent  Gregory Martin International  Engineering Jobs   \n",
        "\n",
        "                                SalaryRaw  SalaryNormalized        SourceName  \n",
        "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
        "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
        "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
        "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
        "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
        "         Id                                              Title  \\\n",
        "1  72629919                  NDT Quality Inspector FPI level 2   \n",
        "2  72629930                             MidLevel NET Developer   \n",
        "3  72629937  C NET **** ASPNET MVC WCF Agile Developer Fina...   \n",
        "4  72629938  Dutch speaking Online Content & marketing Exec...   \n",
        "5  72629944                     IMMIGRATION LAWYERS  MIDDLESEX   \n",
        "\n",
        "                                     FullDescription  \\\n",
        "1  NDT Inspector qualified with FPI Level 2 requi...   \n",
        "2  Skills: .NET, C, VB.NET, MS SQL, jQuery, HTML ...   \n",
        "3  C .NET **** ASP.NET MVC WCF Agile Developer Fi...   \n",
        "4  DUTCH SPEAKING ONLINE CONTENT & MARKETING EXEC...   \n",
        "5  IMMIGRATION LAWYERS  MIDDLESEX THE FIRM Our cl...   \n",
        "\n",
        "                  LocationRaw LocationNormalized ContractType ContractTime  \\\n",
        "1                UK Leicester          Leicester          NaN    permanent   \n",
        "2  Republic of Ireland Dublin                 UK          NaN    permanent   \n",
        "3                   UK London             London          NaN    permanent   \n",
        "4                   UK London             London          NaN    permanent   \n",
        "5                UK Middlesex                 UK          NaN    permanent   \n",
        "\n",
        "                       Company                          Category  \\\n",
        "1     Technical Placements Ltd                  Engineering Jobs   \n",
        "2    Reperio Human Capital Ltd                           IT Jobs   \n",
        "3              Noir Consulting                           IT Jobs   \n",
        "4     Oak Tree Recruitment Ltd  PR, Advertising & Marketing Jobs   \n",
        "5  Law Staff Legal Recruitment                        Legal Jobs   \n",
        "\n",
        "      SourceName  \n",
        "1  careers4a.com  \n",
        "2  careers4a.com  \n",
        "3  careers4a.com  \n",
        "4  careers4a.com  \n",
        "5  careers4a.com  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/arahuja/anaconda/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Modeling in Statsmodels\n",
      "\n",
      "Statsmodels has a reasonable Linear Regression model available. It provides more detail on our model than sckits-learn will, but tends to be slow once our dataset get's bigger.  A big advantage is the simple formula syntax, but we can use patsy's dmatrices/dmatrix function to replace this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.formula.api as sm\n",
      "\n",
      "formula = \"SalaryNormalized ~ Category + ContractTime*ContractType\"\n",
      "model = sm.ols(formula, data=data).fit()\n",
      "\n",
      "print model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:       SalaryNormalized   R-squared:                       0.860\n",
        "Model:                            OLS   Adj. R-squared:                  0.858\n",
        "Method:                 Least Squares   F-statistic:                     380.0\n",
        "Date:                Thu, 10 Jul 2014   Prob (F-statistic):               0.00\n",
        "Time:                        17:58:42   Log-Likelihood:                -20731.\n",
        "No. Observations:                1882   AIC:                         4.152e+04\n",
        "Df Residuals:                    1852   BIC:                         4.169e+04\n",
        "Df Model:                          30                                         \n",
        "=======================================================================================================================\n",
        "                                                          coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "-----------------------------------------------------------------------------------------------------------------------\n",
        "Intercept                                            4.663e+04   1652.276     28.221      0.000      4.34e+04  4.99e+04\n",
        "Category[T.Admin Jobs]                              -2.292e+04   3609.475     -6.351      0.000        -3e+04 -1.58e+04\n",
        "Category[T.Charity & Voluntary Jobs]                -1.815e+04   4094.372     -4.433      0.000     -2.62e+04 -1.01e+04\n",
        "Category[T.Consultancy Jobs]                         -681.0536   3740.407     -0.182      0.856     -8016.910  6654.803\n",
        "Category[T.Creative & Design Jobs]                  -1.639e+04   5343.216     -3.067      0.002     -2.69e+04 -5908.036\n",
        "Category[T.Customer Services Jobs]                  -2.538e+04   2692.699     -9.424      0.000     -3.07e+04 -2.01e+04\n",
        "Category[T.Domestic help & Cleaning Jobs]           -2.087e+04   1.05e+04     -1.981      0.048     -4.15e+04  -209.099\n",
        "Category[T.Energy, Oil & Gas Jobs]                  -1.275e+04   4094.764     -3.115      0.002     -2.08e+04 -4722.627\n",
        "Category[T.Engineering Jobs]                        -1.046e+04   1360.013     -7.692      0.000     -1.31e+04 -7794.014\n",
        "Category[T.Graduate Jobs]                           -4.166e-11   2.05e-11     -2.032      0.042     -8.19e-11 -1.46e-12\n",
        "Category[T.HR & Recruitment Jobs]                   -1.224e+04   2247.588     -5.444      0.000     -1.66e+04 -7827.902\n",
        "Category[T.Healthcare & Nursing Jobs]               -1.158e+04   3143.839     -3.683      0.000     -1.77e+04 -5413.250\n",
        "Category[T.Hospitality & Catering Jobs]             -2.123e+04   2939.555     -7.222      0.000      -2.7e+04 -1.55e+04\n",
        "Category[T.IT Jobs]                                 -2446.6662   1234.722     -1.982      0.048     -4868.259   -25.073\n",
        "Category[T.Legal Jobs]                              -2.509e+04   8632.425     -2.907      0.004      -4.2e+04 -8162.822\n",
        "Category[T.Logistics & Warehouse Jobs]               -1.57e+04   3600.302     -4.362      0.000     -2.28e+04 -8642.197\n",
        "Category[T.Maintenance Jobs]                        -1.415e+04   3651.423     -3.874      0.000     -2.13e+04 -6985.106\n",
        "Category[T.Manufacturing Jobs]                      -1.667e+04   2816.016     -5.919      0.000     -2.22e+04 -1.11e+04\n",
        "Category[T.Other/General Jobs]                       -1.38e+04   1884.617     -7.322      0.000     -1.75e+04 -1.01e+04\n",
        "Category[T.PR, Advertising & Marketing Jobs]        -9496.2472   3260.046     -2.913      0.004     -1.59e+04 -3102.496\n",
        "Category[T.Property Jobs]                           -2.011e+04   8632.425     -2.330      0.020      -3.7e+04 -3182.822\n",
        "Category[T.Retail Jobs]                             -2.027e+04   3965.982     -5.110      0.000      -2.8e+04 -1.25e+04\n",
        "Category[T.Sales Jobs]                              -8789.0703   1866.091     -4.710      0.000     -1.24e+04 -5129.207\n",
        "Category[T.Scientific & QA Jobs]                    -1.245e+04   1764.140     -7.058      0.000     -1.59e+04 -8991.469\n",
        "Category[T.Social work Jobs]                        -2.483e+04   8664.674     -2.865      0.004     -4.18e+04 -7834.476\n",
        "Category[T.Teaching Jobs]                           -1.707e+04   1479.304    -11.537      0.000        -2e+04 -1.42e+04\n",
        "Category[T.Trade & Construction Jobs]               -1.462e+04   1892.867     -7.722      0.000     -1.83e+04 -1.09e+04\n",
        "Category[T.Travel Jobs]                             -2.698e+04   7511.150     -3.592      0.000     -4.17e+04 -1.22e+04\n",
        "ContractTime[T.permanent]                           -1304.7038   1360.325     -0.959      0.338     -3972.636  1363.228\n",
        "ContractType[T.part_time]                           -7671.2094   4062.380     -1.888      0.059     -1.56e+04   296.115\n",
        "ContractTime[T.permanent]:ContractType[T.part_time]  -180.8946   5927.671     -0.031      0.976     -1.18e+04  1.14e+04\n",
        "==============================================================================\n",
        "Omnibus:                      413.221   Durbin-Watson:                   1.686\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              942.225\n",
        "Skew:                           1.219   Prob(JB):                    2.50e-205\n",
        "Kurtosis:                       5.464   Cond. No.                          nan\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] The smallest eigenvalue is -3.64e-15. This might indicate that there are\n",
        "strong multicollinearity problems or that the design matrix is singular.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Modeling sklearn\n",
      "\n",
      "To use scikits-learn, we first need to create our design matrix X from our initial dataframe.  There many way to do this. Once we have that matrix X, we will use model.fit(X, y) to fit the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression, Lasso\n",
      "\n",
      "model = LinearRegression() # alternatively use Lasso() for L1 regularization or Ridge for L2\n",
      "# model = model.fit(X, data.SalaryNormalized) # This won't work yet, until we create X from our dataframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using dmatrices to create the Design Matrix\n",
      "\n",
      "We can use dmatrices to use the formula syntax from before to create the matrices (Alternatively, we can use dmatrix, the only difference is dmatrix doesn't require us to set a out outcome variable, we can just provide the right side of the equation)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from patsy import dmatrix\n",
      "\n",
      "X = dmatrix(\"Category + ContractType*ContractType\", data=data)\n",
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
        " [ 1.  0.  0. ...,  0.  0.  0.]\n",
        " [ 1.  0.  0. ...,  0.  0.  0.]\n",
        " ..., \n",
        " [ 1.  0.  0. ...,  0.  0.  1.]\n",
        " [ 1.  0.  0. ...,  0.  0.  1.]\n",
        " [ 1.  0.  0. ...,  0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using get_dummies to create the design matrix\n",
      "\n",
      "We can also use the Pandas function get_dummies, but we won't be able to automatically get interaction effects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "category_dummies = pd.get_dummies(data.Category)\n",
      "contract_type_dummies = pd.get_dummies(data.ContractType)\n",
      "\n",
      "from numpy import hstack\n",
      "\n",
      "X = hstack((category_dummies,contract_type_dummies))\n",
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " ..., \n",
        " [ 0.  0.  0. ...,  0.  0.  1.]\n",
        " [ 0.  0.  0. ...,  0.  0.  1.]\n",
        " [ 0.  0.  0. ...,  0.  1.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using the Dict Vectorizer to create the design matrix\n",
      "\n",
      "Another option which we haven't seen before is to use another feature extraction tool from sklearn, the DictVectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "dv = DictVectorizer()\n",
      "X = dv.fit_transform(data[['Category']].T.to_dict().values())\n",
      "print X, X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 8)\t1.0\n",
        "  (1, 8)\t1.0\n",
        "  (2, 8)\t1.0\n",
        "  (3, 8)\t1.0\n",
        "  (4, 8)\t1.0\n",
        "  (5, 8)\t1.0\n",
        "  (6, 8)\t1.0\n",
        "  (7, 10)\t1.0\n",
        "  (8, 10)\t1.0\n",
        "  (9, 8)\t1.0\n",
        "  (10, 0)\t1.0\n",
        "  (11, 11)\t1.0\n",
        "  (12, 18)\t1.0\n",
        "  (13, 18)\t1.0\n",
        "  (14, 12)\t1.0\n",
        "  (15, 8)\t1.0\n",
        "  (16, 8)\t1.0\n",
        "  (17, 12)\t1.0\n",
        "  (18, 8)\t1.0\n",
        "  (19, 8)\t1.0\n",
        "  (20, 8)\t1.0\n",
        "  (21, 12)\t1.0\n",
        "  (22, 8)\t1.0\n",
        "  (23, 8)\t1.0\n",
        "  (24, 8)\t1.0\n",
        "  :\t:\n",
        "  (9975, 11)\t1.0\n",
        "  (9976, 11)\t1.0\n",
        "  (9977, 11)\t1.0\n",
        "  (9978, 11)\t1.0\n",
        "  (9979, 11)\t1.0\n",
        "  (9980, 11)\t1.0\n",
        "  (9981, 11)\t1.0\n",
        "  (9982, 11)\t1.0\n",
        "  (9983, 11)\t1.0\n",
        "  (9984, 11)\t1.0\n",
        "  (9985, 11)\t1.0\n",
        "  (9986, 11)\t1.0\n",
        "  (9987, 11)\t1.0\n",
        "  (9988, 11)\t1.0\n",
        "  (9989, 11)\t1.0\n",
        "  (9990, 11)\t1.0\n",
        "  (9991, 11)\t1.0\n",
        "  (9992, 11)\t1.0\n",
        "  (9993, 11)\t1.0\n",
        "  (9994, 11)\t1.0\n",
        "  (9995, 11)\t1.0\n",
        "  (9996, 11)\t1.0\n",
        "  (9997, 11)\t1.0\n",
        "  (9998, 11)\t1.0\n",
        "  (9999, 11)\t1.0 (10000, 28)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train-Test Split\n",
      "\n",
      "We can create a split of OUR training data, to evaluate our model, our features and any parameters we have set.  We want to have some idea of how well we will do on the true test set since we do not know the the true salaries on that set.  That is representative of new data we expect in the future."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, data.SalaryNormalized)\n",
      "\n",
      "model.fit(X_train, y_train)\n",
      "model.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.13821387843783695"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluating using MAE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "predicted_salaries = model.predict(X_test)\n",
      "print mean_absolute_error(y_test, predicted_salaries)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10646.2758676\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.metrics import make_scorer \n",
      "\n",
      "print cross_val_score(model, X, data.SalaryNormalized)\n",
      "\n",
      "print cross_val_score(model, X, data.SalaryNormalized, scoring=make_scorer(mean_absolute_error))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.1015409   0.04431167  0.16798513]\n",
        "[ 10640.49896082  10593.60080815  11305.14610528]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Adding text features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['isManager'] = data.FullDescription.str.lower().map(lambda x: 1 if 'manager' in x else 0)\n",
      "data['isAssistant'] = data.FullDescription.str.lower().map(lambda x: 1 if 'assistant' in x else 0)\n",
      "data['isExecutive'] = data.FullDescription.str.lower().map(lambda x: 1 if 'exec' in x or 'ceo' in x or 'president' in x else 0)\n",
      "\n",
      "X = dmatrix(\"Category + isManager + isAssistant + isExecutive\", data=data)\n",
      "print cross_val_score(model, X, data.SalaryNormalized)\n",
      "print cross_val_score(model, X, data.SalaryNormalized, scoring=make_scorer(mean_absolute_error))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.16976912  0.07820619  0.19462668]\n",
        "[  9945.8084865   10189.04243929  10966.73795979]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parsing out the Location Tree file\n",
      "\n",
      "To parse this file out, we can perform a Depth-First-Search where we each line represents a search from root of a tree to a leaf node.  We can also easily save the parent of the node since it will also be the location we see directly before the node.  Below we create a `parent_lookup` dictionary. We could use this to clean up locations, we could remove locations that do not occur very often and replace them with their parent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(\"Location_Tree.csv\")\n",
      "location_tree = {}\n",
      "parent_lookup = {}\n",
      "for line in f:\n",
      "    branch = line.strip().strip(\"\\\"\").split(\"~\")\n",
      "    parent_tree = location_tree\n",
      "    last_parent = None\n",
      "    for node in branch:\n",
      "        if node in parent_tree:\n",
      "            parent_tree = parent_tree[node]\n",
      "        else:\n",
      "            parent_tree[node] = {}\n",
      "            parent_tree = parent_tree[node]\n",
      "        parent_lookup[node] = last_parent\n",
      "        last_parent = node\n",
      "\n",
      "print parent_lookup['UK']\n",
      "print parent_lookup['London']\n",
      "print parent_lookup['Heathrow Airport']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "UK\n",
        "London\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Capture the most frequently occuring locations\n",
      "location_counts = data.LocationNormalized.value_counts()\n",
      "top_locations = set(location_counts.index[:30])\n",
      "print \"Top locations:\", top_locations\n",
      "\n",
      "# This search_to_top_location will keep moving up the location tree so we can replace any \n",
      "# low occuring location with some parent that occurs more often\n",
      "def search_to_top_location(location, parent_lookup, top_locations):\n",
      "    i = 0\n",
      "    depth_limit = 10\n",
      "    while location not in top_locations and i < depth_limit:\n",
      "        location = parent_lookup[location]\n",
      "        i += 1\n",
      "    return \"OTHER\" if i > depth_limit else location\n",
      "\n",
      "data['BetterLocation'] = data.LocationNormalized.map(lambda x: search_to_top_location(x, parent_lookup, top_locations))\n",
      "\n",
      "X = dmatrix(\"Category + isManager + isAssistant + isExecutive + BetterLocation\", data=data)\n",
      "print cross_val_score(model, X, data.SalaryNormalized)\n",
      "print cross_val_score(model, X, data.SalaryNormalized, scoring=make_scorer(mean_absolute_error))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top locations: set(['Manchester', 'Belfast', 'Berkshire', 'Oxfordshire', 'Hampshire', 'West Yorkshire', 'Wales', 'The City', 'Reading', 'Glasgow', 'Liverpool', 'Sheffield', 'Leeds', 'Birmingham', 'Hertfordshire', 'Bradford', 'Southampton', 'Newcastle Upon Tyne', 'Bristol', 'Lancashire', 'Surrey', 'West Midlands', 'Cambridge', 'Leicester', 'Essex', 'Nottingham', 'Cheshire', 'London', 'UK', 'South East London'])\n",
        "[ 0.1904336   0.14535179  0.25898342]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  9766.58642887   9800.95867893  10558.81238255]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Adding text features automatically using the CountVectorizer\n",
      "\n",
      "The CountVectorizer from sklearn will automatically create text features for us.  This may be easier, but it isn't always better. Picking up on informative word pairs that we can aggregate into useful features like the 'isExecutive' feature may be more valuable and make it easier for our algorithm to learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "cv = CountVectorizer(stop_words = 'english', ngram_range=(1,2), max_features = 1000)\n",
      "description_features = cv.fit_transform(data.FullDescription).todense()\n",
      "\n",
      "X = dmatrix(\"Category + isManager + isAssistant + isExecutive + BetterLocation\", data=data)\n",
      "X = hstack((X, description_features))\n",
      "print cross_val_score(model, X, data.SalaryNormalized)\n",
      "print cross_val_score(model, X, data.SalaryNormalized, scoring=make_scorer(mean_absolute_error))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.36485359  0.3142147   0.17212753]\n",
        "[  8889.2514981    9311.58920523  11027.02945829]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predicting on the held out set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(X, data.SalaryNormalized)\n",
      "\n",
      "# First we need to decided how to create our matrix on the new test set\n",
      "# submissionX = ???\n",
      "\n",
      "# p = model.predict(submissionX).T[0]\n",
      "\n",
      "# create a solution\n",
      "# solution = pd.DataFrame({\"Id\": test.Id, \"Prediction\": p})\n",
      "# solution.to_csv(\"submission_answer.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Option 1: Concat both together first use dmatrices on both\n",
      "\n",
      "#concat both together\n",
      "fullData = pd.concat([data, submission_test])\n",
      "\n",
      "from patsy import dmatrices\n",
      "# Create feature matrix/design matrix from both\n",
      "X = dmatrix(\"Category\", data=fullData, return_type='matrix')\n",
      "\n",
      "#resplit into training and test\n",
      "trainX = X[:len(data)]\n",
      "trainY = data.SalaryNormalized\n",
      "submissionX = X[len(data):]\n",
      "\n",
      "model.fit(trainX, trainY)\n",
      "p = model.predict(submissionX)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Option 2: Use sklearns fit_transform and transform functions\n",
      "\n",
      "# Create your vectorizers and use fit_transform on the training set\n",
      "category_dv = DictVectorizer()\n",
      "train_category_features = category_dv.fit_transform(data[['Category']].T.to_dict().values()).todense()\n",
      "description_cv = CountVectorizer(stop_words='english', max_features=1000)\n",
      "train_description_features = description_cv.fit_transform(data.FullDescription).todense()\n",
      "\n",
      "trainX = hstack((train_category_features, train_description_features))\n",
      "trainY = data.SalaryNormalized\n",
      "\n",
      "print trainX.shape\n",
      "\n",
      "# Use .tranform on the test set, no need to `fit` again\n",
      "test_category_features = category_dv.transform(submission_test[['Category']].T.to_dict().values()).todense()\n",
      "test_description_features = description_cv.transform(submission_test.FullDescription).todense()\n",
      "\n",
      "submissionX =  hstack((test_category_features, test_description_features))\n",
      "\n",
      "model.fit(trainX, trainY)\n",
      "p = model.predict(submissionX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10000, 1028)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a solution\n",
      "solution = pd.DataFrame({\"Id\": submission_test.Id, \"Prediction\": p})\n",
      "solution.to_csv(\"submission_answer.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}